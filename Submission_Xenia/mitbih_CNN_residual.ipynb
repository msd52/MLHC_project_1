{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4accc8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras import optimizers, losses, activations, models\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.python.keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate, Flatten\n",
    "from sklearn.metrics import f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5838d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"C:/00ETH/ml4h/Project1/archive/mitbih_train.csv\", header=None)\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_test = pd.read_csv(\"C:/00ETH/ml4h/Project1/archive/mitbih_test.csv\", header=None)\n",
    "\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ece6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(x,filter):\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv1D(filter[0], kernel_size=5, padding = 'same')(x)\n",
    "    x = tf.keras.layers.Conv1D(filter[0], kernel_size=5, padding = 'same')(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv1D(filter[1], kernel_size=3, padding = 'same')(x)\n",
    "    x = tf.keras.layers.Conv1D(filter[1], kernel_size=3, padding = 'same')(x)  \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d074e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(x, filter):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv1D(filter[0], kernel_size=3, padding = 'same')(x)\n",
    "    x = tf.keras.layers.Conv1D(filter[0], kernel_size=3, padding = 'same')(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv1D(filter[1], kernel_size=3, padding = 'same')(x)\n",
    "    x = tf.keras.layers.Conv1D(filter[1], kernel_size=3, padding = 'same')(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv1D(filter[1], kernel_size=3, padding = 'same')(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc774d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model1():\n",
    "    nclass = 5\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = tf.keras.layers.Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"same\")(inp)\n",
    "    img_1 = tf.keras.layers.Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"same\")(img_1)\n",
    "    img_1 = tf.keras.layers.MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = tf.keras.layers.Dropout(rate=0.1)(img_1)\n",
    "    \n",
    "    img_shortcut = convolutional_block(img_1,[32,32])\n",
    "    img_shortcut = identity_block(img_shortcut,[32,32])\n",
    "\n",
    "    img_1 = tf.keras.layers.Conv1D(256, kernel_size=3, padding = 'same')(img_shortcut)\n",
    "    img_1 = tf.keras.layers.Conv1D(256, kernel_size=3, padding = 'same')(img_1)\n",
    "    img_1 = tf.keras.layers.Activation('relu')(img_1)\n",
    "    img_1 = Flatten()(img_1)\n",
    "\n",
    "    dense_1 = tf.keras.layers.Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = tf.keras.layers.Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = tf.keras.layers.Dense(nclass, activation=activations.softmax, name=\"dense_3_mitbih\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6b33ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 187, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_264 (Conv1D)             (None, 187, 16)      96          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_265 (Conv1D)             (None, 187, 16)      1296        conv1d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 93, 16)       0           conv1d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 93, 16)       0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_266 (Conv1D)             (None, 93, 32)       1568        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_267 (Conv1D)             (None, 93, 32)       3104        conv1d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 93, 32)       0           conv1d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_268 (Conv1D)             (None, 93, 32)       3104        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_269 (Conv1D)             (None, 93, 32)       3104        conv1d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_270 (Conv1D)             (None, 93, 32)       1568        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 93, 32)       0           conv1d_269[0][0]                 \n",
      "                                                                 conv1d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 93, 32)       0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_271 (Conv1D)             (None, 93, 32)       5152        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_272 (Conv1D)             (None, 93, 32)       5152        conv1d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 93, 32)       0           conv1d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_273 (Conv1D)             (None, 93, 32)       3104        activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_274 (Conv1D)             (None, 93, 32)       3104        conv1d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 93, 32)       0           conv1d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 93, 32)       0           activation_111[0][0]             \n",
      "                                                                 activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 93, 32)       0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_275 (Conv1D)             (None, 93, 256)      24832       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_276 (Conv1D)             (None, 93, 256)      196864      conv1d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 93, 256)      0           conv1d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 23808)        0           activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           1523776     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3_mitbih (Dense)          (None, 5)            325         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,780,309\n",
      "Trainable params: 1,780,309\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = get_model1()\n",
    "file_path = \"Resnet_cnn_mitbih1.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfda64c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/1000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.97202, saving model to Resnet_cnn_mitbih1.h5\n",
      "78798/78798 - 165s - loss: 0.1681 - acc: 0.9546 - val_loss: 0.0997 - val_acc: 0.9720\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.97202 to 0.97533, saving model to Resnet_cnn_mitbih1.h5\n",
      "78798/78798 - 142s - loss: 0.0963 - acc: 0.9724 - val_loss: 0.0864 - val_acc: 0.9753\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.97533 to 0.97750, saving model to Resnet_cnn_mitbih1.h5\n",
      "78798/78798 - 140s - loss: 0.0792 - acc: 0.9764 - val_loss: 0.0787 - val_acc: 0.9775\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.97750 to 0.97796, saving model to Resnet_cnn_mitbih1.h5\n",
      "78798/78798 - 142s - loss: 0.0676 - acc: 0.9800 - val_loss: 0.0724 - val_acc: 0.9780\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.97796\n",
      "78798/78798 - 147s - loss: 0.0592 - acc: 0.9825 - val_loss: 0.0729 - val_acc: 0.9768\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97796\n",
      "78798/78798 - 141s - loss: 0.0509 - acc: 0.9841 - val_loss: 0.0870 - val_acc: 0.9774\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.97796 to 0.98218, saving model to Resnet_cnn_mitbih1.h5\n",
      "78798/78798 - 140s - loss: 0.0462 - acc: 0.9859 - val_loss: 0.0666 - val_acc: 0.9822\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98218\n",
      "78798/78798 - 138s - loss: 0.0408 - acc: 0.9874 - val_loss: 0.0745 - val_acc: 0.9808\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98218\n",
      "78798/78798 - 137s - loss: 0.0365 - acc: 0.9883 - val_loss: 0.0744 - val_acc: 0.9814\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98218\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "78798/78798 - 138s - loss: 0.0355 - acc: 0.9886 - val_loss: 0.0847 - val_acc: 0.9782\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.98218 to 0.98515, saving model to Resnet_cnn_mitbih1.h5\n",
      "78798/78798 - 137s - loss: 0.0179 - acc: 0.9939 - val_loss: 0.0665 - val_acc: 0.9852\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.98515 to 0.98561, saving model to Resnet_cnn_mitbih1.h5\n",
      "78798/78798 - 137s - loss: 0.0129 - acc: 0.9954 - val_loss: 0.0687 - val_acc: 0.9856\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.98561 to 0.98630, saving model to Resnet_cnn_mitbih1.h5\n",
      "78798/78798 - 137s - loss: 0.0112 - acc: 0.9961 - val_loss: 0.0711 - val_acc: 0.9863\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98630\n",
      "78798/78798 - 136s - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0747 - val_acc: 0.9862\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98630\n",
      "78798/78798 - 137s - loss: 0.0086 - acc: 0.9969 - val_loss: 0.0833 - val_acc: 0.9860\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98630\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "78798/78798 - 137s - loss: 0.0071 - acc: 0.9974 - val_loss: 0.0823 - val_acc: 0.9858\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.98630 to 0.98652, saving model to Resnet_cnn_mitbih1.h5\n",
      "78798/78798 - 138s - loss: 0.0060 - acc: 0.9979 - val_loss: 0.0848 - val_acc: 0.9865\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.98652 to 0.98675, saving model to Resnet_cnn_mitbih1.h5\n",
      "78798/78798 - 138s - loss: 0.0057 - acc: 0.9979 - val_loss: 0.0839 - val_acc: 0.9868\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.98675\n",
      "78798/78798 - 141s - loss: 0.0054 - acc: 0.9980 - val_loss: 0.0859 - val_acc: 0.9864\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.98675\n",
      "78798/78798 - 137s - loss: 0.0054 - acc: 0.9981 - val_loss: 0.0852 - val_acc: 0.9865\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.98675\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "78798/78798 - 137s - loss: 0.0055 - acc: 0.9981 - val_loss: 0.0864 - val_acc: 0.9864\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.98675\n",
      "78798/78798 - 137s - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0865 - val_acc: 0.9865\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.98675\n",
      "78798/78798 - 137s - loss: 0.0054 - acc: 0.9981 - val_loss: 0.0865 - val_acc: 0.9865\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "model1.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model1.load_weights(file_path)\n",
    "\n",
    "pred_test = model1.predict(X_test)\n",
    "pred_test = np.argmax(pred_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c4b9ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9198314392793776 \n",
      "Test accuracy score : 0.985108715512516 \n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(Y_test, pred_test, average=\"macro\")\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f67f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model2():\n",
    "    nclass = 5\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = tf.keras.layers.Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"same\")(inp)\n",
    "    img_1 = tf.keras.layers.Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"same\")(img_1)\n",
    "    img_1 = tf.keras.layers.MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = tf.keras.layers.Dropout(rate=0.1)(img_1)\n",
    "    \n",
    "    img_shortcut = convolutional_block(img_1,[32,32])\n",
    "    \n",
    "    img_1 = tf.keras.layers.Conv1D(256, kernel_size=3, padding = 'same')(img_shortcut)\n",
    "    img_1 = tf.keras.layers.Conv1D(256, kernel_size=3, padding = 'same')(img_1)\n",
    "    img_1 = tf.keras.layers.Activation('relu')(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "\n",
    "    dense_1 = tf.keras.layers.Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = tf.keras.layers.Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = tf.keras.layers.Dense(nclass, activation=activations.softmax, name=\"dense_3_mitbih\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f19a061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 187, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_277 (Conv1D)             (None, 187, 16)      96          input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_278 (Conv1D)             (None, 187, 16)      1296        conv1d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 93, 16)       0           conv1d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 93, 16)       0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_279 (Conv1D)             (None, 93, 32)       1568        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_280 (Conv1D)             (None, 93, 32)       3104        conv1d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 93, 32)       0           conv1d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_281 (Conv1D)             (None, 93, 32)       3104        activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_282 (Conv1D)             (None, 93, 32)       3104        conv1d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_283 (Conv1D)             (None, 93, 32)       1568        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 93, 32)       0           conv1d_282[0][0]                 \n",
      "                                                                 conv1d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 93, 32)       0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_284 (Conv1D)             (None, 93, 256)      24832       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_285 (Conv1D)             (None, 93, 256)      196864      conv1d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 93, 256)      0           conv1d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 256)          0           activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16448       global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3_mitbih (Dense)          (None, 5)            325         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 256,469\n",
      "Trainable params: 256,469\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = get_model2()\n",
    "file_path = \"Resnet_cnn_mitbih2.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8762eae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/1000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.96836, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 111s - loss: 0.2308 - acc: 0.9373 - val_loss: 0.1254 - val_acc: 0.9684\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.96836 to 0.97145, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 106s - loss: 0.1395 - acc: 0.9617 - val_loss: 0.1063 - val_acc: 0.9714\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.97145 to 0.97213, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 106s - loss: 0.1217 - acc: 0.9665 - val_loss: 0.1079 - val_acc: 0.9721\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.97213 to 0.97339, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 109s - loss: 0.1095 - acc: 0.9702 - val_loss: 0.0982 - val_acc: 0.9734\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97339 to 0.97487, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 108s - loss: 0.1036 - acc: 0.9722 - val_loss: 0.0902 - val_acc: 0.9749\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.97487 to 0.97590, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 110s - loss: 0.0978 - acc: 0.9724 - val_loss: 0.0925 - val_acc: 0.9759\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.97590\n",
      "78798/78798 - 107s - loss: 0.0930 - acc: 0.9741 - val_loss: 0.0853 - val_acc: 0.9759\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.97590 to 0.97613, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 106s - loss: 0.0895 - acc: 0.9751 - val_loss: 0.0905 - val_acc: 0.9761\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.97613\n",
      "78798/78798 - 107s - loss: 0.0883 - acc: 0.9754 - val_loss: 0.0833 - val_acc: 0.9761\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.97613 to 0.97716, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 108s - loss: 0.0846 - acc: 0.9767 - val_loss: 0.0871 - val_acc: 0.9772\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.97716\n",
      "78798/78798 - 102s - loss: 0.0824 - acc: 0.9772 - val_loss: 0.0789 - val_acc: 0.9765\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.97716 to 0.97841, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 102s - loss: 0.0807 - acc: 0.9774 - val_loss: 0.0767 - val_acc: 0.9784\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.97841 to 0.98036, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 103s - loss: 0.0789 - acc: 0.9784 - val_loss: 0.0795 - val_acc: 0.9804\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98036\n",
      "78798/78798 - 103s - loss: 0.0777 - acc: 0.9789 - val_loss: 0.0759 - val_acc: 0.9793\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98036\n",
      "78798/78798 - 103s - loss: 0.0774 - acc: 0.9787 - val_loss: 0.0868 - val_acc: 0.9781\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98036\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "78798/78798 - 104s - loss: 0.0743 - acc: 0.9795 - val_loss: 0.0775 - val_acc: 0.9800\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.98036 to 0.98298, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 104s - loss: 0.0559 - acc: 0.9845 - val_loss: 0.0643 - val_acc: 0.9830\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.98298 to 0.98344, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 104s - loss: 0.0511 - acc: 0.9861 - val_loss: 0.0623 - val_acc: 0.9834\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.98344 to 0.98401, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 104s - loss: 0.0484 - acc: 0.9863 - val_loss: 0.0630 - val_acc: 0.9840\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.98401\n",
      "78798/78798 - 104s - loss: 0.0470 - acc: 0.9867 - val_loss: 0.0602 - val_acc: 0.9840\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.98401\n",
      "78798/78798 - 105s - loss: 0.0447 - acc: 0.9871 - val_loss: 0.0608 - val_acc: 0.9839\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.98401 to 0.98435, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 105s - loss: 0.0449 - acc: 0.9873 - val_loss: 0.0585 - val_acc: 0.9844\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.98435 to 0.98447, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 105s - loss: 0.0433 - acc: 0.9877 - val_loss: 0.0593 - val_acc: 0.9845\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.98447\n",
      "78798/78798 - 123s - loss: 0.0426 - acc: 0.9877 - val_loss: 0.0593 - val_acc: 0.9840\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.98447\n",
      "78798/78798 - 106s - loss: 0.0404 - acc: 0.9880 - val_loss: 0.0613 - val_acc: 0.9844\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.98447 to 0.98458, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 104s - loss: 0.0404 - acc: 0.9881 - val_loss: 0.0611 - val_acc: 0.9846\n",
      "Epoch 27/1000\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.98458\n",
      "78798/78798 - 104s - loss: 0.0403 - acc: 0.9881 - val_loss: 0.0605 - val_acc: 0.9845\n",
      "Epoch 28/1000\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.98458\n",
      "78798/78798 - 105s - loss: 0.0386 - acc: 0.9889 - val_loss: 0.0609 - val_acc: 0.9846\n",
      "Epoch 29/1000\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.98458\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "78798/78798 - 105s - loss: 0.0379 - acc: 0.9889 - val_loss: 0.0609 - val_acc: 0.9845\n",
      "Epoch 30/1000\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.98458 to 0.98504, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 108s - loss: 0.0362 - acc: 0.9893 - val_loss: 0.0598 - val_acc: 0.9850\n",
      "Epoch 31/1000\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.98504 to 0.98527, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 106s - loss: 0.0353 - acc: 0.9896 - val_loss: 0.0595 - val_acc: 0.9853\n",
      "Epoch 32/1000\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.98527 to 0.98561, saving model to Resnet_cnn_mitbih2.h5\n",
      "78798/78798 - 106s - loss: 0.0347 - acc: 0.9893 - val_loss: 0.0594 - val_acc: 0.9856\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.98561\n",
      "78798/78798 - 104s - loss: 0.0348 - acc: 0.9896 - val_loss: 0.0595 - val_acc: 0.9854\n",
      "Epoch 34/1000\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.98561\n",
      "78798/78798 - 104s - loss: 0.0345 - acc: 0.9897 - val_loss: 0.0592 - val_acc: 0.9855\n",
      "Epoch 35/1000\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.98561\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "78798/78798 - 105s - loss: 0.0348 - acc: 0.9898 - val_loss: 0.0592 - val_acc: 0.9855\n",
      "Epoch 36/1000\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.98561\n",
      "78798/78798 - 106s - loss: 0.0343 - acc: 0.9895 - val_loss: 0.0592 - val_acc: 0.9854\n",
      "Epoch 37/1000\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.98561\n",
      "78798/78798 - 105s - loss: 0.0343 - acc: 0.9898 - val_loss: 0.0591 - val_acc: 0.9855\n",
      "Epoch 00037: early stopping\n"
     ]
    }
   ],
   "source": [
    "model2.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model2.load_weights(file_path)\n",
    "\n",
    "pred_test2 = model2.predict(X_test)\n",
    "pred_test2 = np.argmax(pred_test2, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6995e8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9065457524254107 \n",
      "Test accuracy score : 0.9841951397770875 \n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(Y_test, pred_test2, average=\"macro\")\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test2)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9201dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model3():\n",
    "    nclass = 5\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = tf.keras.layers.Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"same\")(inp)\n",
    "    img_1 = tf.keras.layers.Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"same\")(img_1)\n",
    "    img_1 = tf.keras.layers.MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = tf.keras.layers.Dropout(rate=0.1)(img_1)\n",
    "    \n",
    "    img_1 = tf.keras.layers.Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"same\")(img_1)\n",
    "    img_1 = tf.keras.layers.Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"same\")(img_1)\n",
    "    img_1 = tf.keras.layers.MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = tf.keras.layers.Dropout(rate=0.1)(img_1)\n",
    "    \n",
    "    img_shortcut = identity_block(img_1,[32,32])\n",
    "    \n",
    "    img_1 = tf.keras.layers.Conv1D(256, kernel_size=3, padding = 'same')(img_shortcut)\n",
    "    img_1 = tf.keras.layers.Conv1D(256, kernel_size=3, padding = 'same')(img_1)\n",
    "    img_1 = tf.keras.layers.Activation('relu')(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "\n",
    "    dense_1 = tf.keras.layers.Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = tf.keras.layers.Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = tf.keras.layers.Dense(nclass, activation=activations.softmax, name=\"dense_3_mitbih\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8077913c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 187, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_290 (Conv1D)             (None, 187, 16)      96          input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_291 (Conv1D)             (None, 187, 16)      1296        conv1d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 93, 16)       0           conv1d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 93, 16)       0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_292 (Conv1D)             (None, 93, 32)       1568        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_293 (Conv1D)             (None, 93, 32)       3104        conv1d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 46, 32)       0           conv1d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 46, 32)       0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_294 (Conv1D)             (None, 46, 32)       5152        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_295 (Conv1D)             (None, 46, 32)       5152        conv1d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 46, 32)       0           conv1d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_296 (Conv1D)             (None, 46, 32)       3104        activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_297 (Conv1D)             (None, 46, 32)       3104        conv1d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 46, 32)       0           conv1d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 46, 32)       0           activation_118[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 46, 32)       0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_298 (Conv1D)             (None, 46, 256)      24832       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_299 (Conv1D)             (None, 46, 256)      196864      conv1d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 46, 256)      0           conv1d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 256)          0           activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16448       global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3_mitbih (Dense)          (None, 5)            325         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 265,205\n",
      "Trainable params: 265,205\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = get_model3()\n",
    "file_path = \"Resnet_cnn_mitbih3.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "318355bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/1000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95215, saving model to Resnet_cnn_mitbih3.h5\n",
      "78798/78798 - 80s - loss: 0.2529 - acc: 0.9302 - val_loss: 0.1679 - val_acc: 0.9521\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.95215 to 0.96722, saving model to Resnet_cnn_mitbih3.h5\n",
      "78798/78798 - 74s - loss: 0.1419 - acc: 0.9613 - val_loss: 0.1178 - val_acc: 0.9672\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.96722\n",
      "78798/78798 - 74s - loss: 0.1151 - acc: 0.9693 - val_loss: 0.1191 - val_acc: 0.9633\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.96722 to 0.97682, saving model to Resnet_cnn_mitbih3.h5\n",
      "78798/78798 - 75s - loss: 0.1018 - acc: 0.9721 - val_loss: 0.0862 - val_acc: 0.9768\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.97682\n",
      "78798/78798 - 74s - loss: 0.0912 - acc: 0.9747 - val_loss: 0.0841 - val_acc: 0.9765\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.97682 to 0.97921, saving model to Resnet_cnn_mitbih3.h5\n",
      "78798/78798 - 74s - loss: 0.0858 - acc: 0.9757 - val_loss: 0.0791 - val_acc: 0.9792\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.97921\n",
      "78798/78798 - 74s - loss: 0.0800 - acc: 0.9771 - val_loss: 0.0712 - val_acc: 0.9792\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.97921\n",
      "78798/78798 - 74s - loss: 0.0765 - acc: 0.9781 - val_loss: 0.0768 - val_acc: 0.9751\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.97921\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "78798/78798 - 76s - loss: 0.0745 - acc: 0.9785 - val_loss: 0.0831 - val_acc: 0.9772\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.97921 to 0.98641, saving model to Resnet_cnn_mitbih3.h5\n",
      "78798/78798 - 76s - loss: 0.0492 - acc: 0.9852 - val_loss: 0.0507 - val_acc: 0.9864\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.98641 to 0.98744, saving model to Resnet_cnn_mitbih3.h5\n",
      "78798/78798 - 76s - loss: 0.0423 - acc: 0.9875 - val_loss: 0.0483 - val_acc: 0.9874\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98744\n",
      "78798/78798 - 76s - loss: 0.0392 - acc: 0.9883 - val_loss: 0.0487 - val_acc: 0.9863\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98744\n",
      "78798/78798 - 76s - loss: 0.0369 - acc: 0.9885 - val_loss: 0.0489 - val_acc: 0.9865\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98744\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "78798/78798 - 77s - loss: 0.0349 - acc: 0.9891 - val_loss: 0.0494 - val_acc: 0.9873\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.98744 to 0.98835, saving model to Resnet_cnn_mitbih3.h5\n",
      "78798/78798 - 76s - loss: 0.0322 - acc: 0.9897 - val_loss: 0.0460 - val_acc: 0.9884\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98835\n",
      "78798/78798 - 76s - loss: 0.0311 - acc: 0.9903 - val_loss: 0.0467 - val_acc: 0.9880\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.98835\n",
      "78798/78798 - 76s - loss: 0.0312 - acc: 0.9904 - val_loss: 0.0470 - val_acc: 0.9876\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.98835\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "78798/78798 - 76s - loss: 0.0306 - acc: 0.9902 - val_loss: 0.0470 - val_acc: 0.9879\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.98835\n",
      "78798/78798 - 76s - loss: 0.0300 - acc: 0.9903 - val_loss: 0.0470 - val_acc: 0.9878\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.98835\n",
      "78798/78798 - 77s - loss: 0.0302 - acc: 0.9904 - val_loss: 0.0470 - val_acc: 0.9881\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "model3.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model3.load_weights(file_path)\n",
    "\n",
    "pred_test3 = model3.predict(X_test)\n",
    "pred_test3 = np.argmax(pred_test3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c31225cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9171564726806969 \n",
      "Test accuracy score : 0.9854741458066874 \n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(Y_test, pred_test3, average=\"macro\")\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test3)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad12386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
