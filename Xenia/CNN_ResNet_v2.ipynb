{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4accc8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras import optimizers, losses, activations, models\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.python.keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate\n",
    "from sklearn.metrics import f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5838d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"C:/00ETH/ml4h/Project1/archive/mitbih_train.csv\", header=None)\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_test = pd.read_csv(\"C:/00ETH/ml4h/Project1/archive/mitbih_test.csv\", header=None)\n",
    "\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ece6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(x,filter):\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv1D(filter, kernel_size=5, padding = 'same')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization(axis=2)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv1D(filter, kernel_size=3, padding = 'same')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization(axis=2)(x)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d074e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(x, filter):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv1D(filter, kernel_size=5, padding = 'same')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization(axis=1)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv1D(filter, kernel_size=3, padding = 'same')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization(axis=1)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv1D(filter, kernel_size=3, padding = 'same')(x_skip)\n",
    "    #x_skip = tf.keras.layers.BatchNormalization(axis=1)(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc774d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    nclass = 5\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = tf.keras.layers.Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"same\")(inp)\n",
    "    img_1 = tf.keras.layers.Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"same\")(img_1)\n",
    "    img_1 = tf.keras.layers.MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = tf.keras.layers.Dropout(rate=0.1)(img_1)\n",
    "           \n",
    "    img_1 = identity_block(img_1,16)\n",
    "        \n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"same\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"same\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    \n",
    "    img_1 = convolutional_block(img_1,256)\n",
    "    \n",
    "    img_1 = tf.keras.layers.Conv1D(256, kernel_size=3, padding = 'same')(img_1)\n",
    "    img_1 = tf.keras.layers.Conv1D(256, kernel_size=3, padding = 'same')(img_1)\n",
    "    img_1 = tf.keras.layers.Activation('relu')(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = tf.keras.layers.Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = tf.keras.layers.Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = tf.keras.layers.Dense(nclass, activation=activations.softmax, name=\"dense_3_mitbih\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6b33ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 187, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 187, 16)      96          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 187, 16)      1296        conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 93, 16)       0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 93, 16)       0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 93, 16)       1296        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 93, 16)       0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 93, 16)       784         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 93, 16)       0           conv1d_46[0][0]                  \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 93, 16)       0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 93, 32)       1568        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 93, 32)       3104        conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 46, 32)       0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 46, 32)       0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 46, 256)      41216       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 46, 256)      0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 46, 256)      196864      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 46, 256)      0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 46, 256)      24832       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 46, 256)      0           activation_23[0][0]              \n",
      "                                                                 conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 46, 256)      0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 46, 256)      196864      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 46, 256)      196864      conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 46, 256)      0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 256)          0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 256)          0           global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16448       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3_mitbih (Dense)          (None, 5)            325         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 685,717\n",
      "Trainable params: 685,717\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "file_path = \"baseline_cnn_mitbih.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfda64c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/1000\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.97921 to 0.97967, saving model to baseline_cnn_mitbih.h5\n",
      "78798/78798 - 82s - loss: 0.0892 - acc: 0.9757 - val_loss: 0.0698 - val_acc: 0.9797\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.97967 to 0.98298, saving model to baseline_cnn_mitbih.h5\n",
      "78798/78798 - 85s - loss: 0.0834 - acc: 0.9771 - val_loss: 0.0647 - val_acc: 0.9830\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.98298\n",
      "78798/78798 - 85s - loss: 0.0804 - acc: 0.9776 - val_loss: 0.0636 - val_acc: 0.9826\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98298\n",
      "78798/78798 - 85s - loss: 0.0770 - acc: 0.9786 - val_loss: 0.0662 - val_acc: 0.9824\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.98298 to 0.98515, saving model to baseline_cnn_mitbih.h5\n",
      "78798/78798 - 85s - loss: 0.0732 - acc: 0.9794 - val_loss: 0.0541 - val_acc: 0.9852\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98515\n",
      "78798/78798 - 85s - loss: 0.0725 - acc: 0.9790 - val_loss: 0.0621 - val_acc: 0.9837\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98515\n",
      "78798/78798 - 85s - loss: 0.0711 - acc: 0.9802 - val_loss: 0.0559 - val_acc: 0.9840\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98515\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "78798/78798 - 85s - loss: 0.0703 - acc: 0.9800 - val_loss: 0.0624 - val_acc: 0.9809\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.98515 to 0.98744, saving model to baseline_cnn_mitbih.h5\n",
      "78798/78798 - 85s - loss: 0.0505 - acc: 0.9849 - val_loss: 0.0412 - val_acc: 0.9874\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.98744\n",
      "78798/78798 - 85s - loss: 0.0430 - acc: 0.9869 - val_loss: 0.0404 - val_acc: 0.9874\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.98744 to 0.98801, saving model to baseline_cnn_mitbih.h5\n",
      "78798/78798 - 85s - loss: 0.0402 - acc: 0.9879 - val_loss: 0.0387 - val_acc: 0.9880\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.98801 to 0.98812, saving model to baseline_cnn_mitbih.h5\n",
      "78798/78798 - 85s - loss: 0.0381 - acc: 0.9884 - val_loss: 0.0382 - val_acc: 0.9881\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98812\n",
      "78798/78798 - 85s - loss: 0.0363 - acc: 0.9883 - val_loss: 0.0382 - val_acc: 0.9881\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.98812 to 0.98824, saving model to baseline_cnn_mitbih.h5\n",
      "78798/78798 - 85s - loss: 0.0348 - acc: 0.9891 - val_loss: 0.0395 - val_acc: 0.9882\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.98824 to 0.98881, saving model to baseline_cnn_mitbih.h5\n",
      "78798/78798 - 85s - loss: 0.0341 - acc: 0.9896 - val_loss: 0.0384 - val_acc: 0.9888\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98881\n",
      "78798/78798 - 85s - loss: 0.0338 - acc: 0.9895 - val_loss: 0.0382 - val_acc: 0.9887\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.98881\n",
      "78798/78798 - 85s - loss: 0.0322 - acc: 0.9900 - val_loss: 0.0369 - val_acc: 0.9885\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.98881\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "78798/78798 - 85s - loss: 0.0314 - acc: 0.9903 - val_loss: 0.0371 - val_acc: 0.9887\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.98881\n",
      "78798/78798 - 85s - loss: 0.0294 - acc: 0.9908 - val_loss: 0.0362 - val_acc: 0.9886\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.98881 to 0.98892, saving model to baseline_cnn_mitbih.h5\n",
      "78798/78798 - 85s - loss: 0.0293 - acc: 0.9908 - val_loss: 0.0361 - val_acc: 0.9889\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.98892 to 0.98915, saving model to baseline_cnn_mitbih.h5\n",
      "78798/78798 - 85s - loss: 0.0291 - acc: 0.9908 - val_loss: 0.0359 - val_acc: 0.9892\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.98915\n",
      "78798/78798 - 85s - loss: 0.0288 - acc: 0.9909 - val_loss: 0.0364 - val_acc: 0.9890\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.98915\n",
      "78798/78798 - 85s - loss: 0.0281 - acc: 0.9910 - val_loss: 0.0361 - val_acc: 0.9888\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.98915\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "78798/78798 - 85s - loss: 0.0279 - acc: 0.9913 - val_loss: 0.0359 - val_acc: 0.9887\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.98915\n",
      "78798/78798 - 85s - loss: 0.0277 - acc: 0.9909 - val_loss: 0.0360 - val_acc: 0.9888\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.98915\n",
      "78798/78798 - 85s - loss: 0.0284 - acc: 0.9911 - val_loss: 0.0360 - val_acc: 0.9888\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model.predict(X_test)\n",
    "pred_test = np.argmax(pred_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c4b9ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9258927990223744 \n",
      "Test accuracy score : 0.9867988306230586 \n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(Y_test, pred_test, average=\"macro\")\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67f584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
