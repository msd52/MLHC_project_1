{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9f227ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras import optimizers, losses, activations, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, concatenate, SimpleRNN, LSTM\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e67541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"C:/00ETH/ml4h/Project1/archive/ptbdb_normal.csv\", header=None)\n",
    "df_2 = pd.read_csv(\"C:/00ETH/ml4h/Project1/archive/ptbdb_abnormal.csv\", header=None)\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
    "\n",
    "\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0503eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucroc = AUC(curve='ROC')\n",
    "aucpr = AUC(curve='PR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0de8c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model1():\n",
    "    nclass = 1\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=[aucroc,aucpr,'acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6bda5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model2():\n",
    "    nclass = 1\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=4, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=4, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=4, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=4, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)   \n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=[aucroc,aucpr,'acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7122e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model3():\n",
    "    nclass = 1\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=[aucroc,aucpr,'acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3031cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model4():\n",
    "    nclass = 1\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=[aucroc,aucpr,'acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c96430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model5():\n",
    "    nclass = 1\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(16, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(16, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(16, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)    \n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)    \n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=[aucroc,aucpr,'acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model6():\n",
    "    nclass = 1\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "915ff986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model7():\n",
    "    nclass = 1\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=[aucroc,aucpr,'acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69d2a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model8():\n",
    "    nclass = 1\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)    \n",
    "    img_1 = Convolution1D(256, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b5cd975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model9():\n",
    "    nclass = 1\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(16, kernel_size=4, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(16, kernel_size=4, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)   \n",
    "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(128, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1) \n",
    "    img_1 = Convolution1D(128, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(128, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)     \n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1) \n",
    "    img_1 = Convolution1D(256, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd4de037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model10():\n",
    "    nclass = 1\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=4, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=4, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=4, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=4, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=4, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1) \n",
    "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)     \n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)    \n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1) \n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_4_ptbdb\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b390a390",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0992c67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 187, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 183, 16)           96        \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 179, 16)           1296      \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 175, 16)           1296      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 87, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 87, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 85, 32)            1568      \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 83, 32)            3104      \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 81, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 38, 32)            3104      \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 36, 32)            3104      \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 34, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 17, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 17, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 15, 256)           24832     \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 13, 256)           196864    \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 11, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 459,009\n",
      "Trainable params: 459,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = get_model1()\n",
    "file_path = \"model1_cnn_ptbdb.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9ee2498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85494, saving model to baseline_cnn_ptbdb.h5\n",
      "10476/10476 - 19s - loss: 0.4807 - auc_2: 0.7848 - auc_3: 0.9012 - acc: 0.7764 - val_loss: 0.3804 - val_auc_2: 0.9000 - val_auc_3: 0.9429 - val_acc: 0.8549\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.85494\n",
      "10476/10476 - 11s - loss: 0.3446 - auc_2: 0.8996 - auc_3: 0.9503 - acc: 0.8632 - val_loss: 0.3923 - val_auc_2: 0.8965 - val_auc_3: 0.9510 - val_acc: 0.8215\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.85494 to 0.90472, saving model to baseline_cnn_ptbdb.h5\n",
      "10476/10476 - 11s - loss: 0.2817 - auc_2: 0.9338 - auc_3: 0.9696 - acc: 0.8918 - val_loss: 0.2479 - val_auc_2: 0.9553 - val_auc_3: 0.9794 - val_acc: 0.9047\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90472\n",
      "10476/10476 - 10s - loss: 0.2233 - auc_2: 0.9584 - auc_3: 0.9822 - acc: 0.9161 - val_loss: 0.2631 - val_auc_2: 0.9638 - val_auc_3: 0.9804 - val_acc: 0.9021\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.90472 to 0.93648, saving model to baseline_cnn_ptbdb.h5\n",
      "10476/10476 - 11s - loss: 0.1950 - auc_2: 0.9678 - auc_3: 0.9861 - acc: 0.9277 - val_loss: 0.1480 - val_auc_2: 0.9833 - val_auc_3: 0.9927 - val_acc: 0.9365\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.93648 to 0.94335, saving model to baseline_cnn_ptbdb.h5\n",
      "10476/10476 - 11s - loss: 0.1633 - auc_2: 0.9772 - auc_3: 0.9903 - acc: 0.9415 - val_loss: 0.1405 - val_auc_2: 0.9870 - val_auc_3: 0.9943 - val_acc: 0.9433\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.94335 to 0.95622, saving model to baseline_cnn_ptbdb.h5\n",
      "10476/10476 - 11s - loss: 0.1510 - auc_2: 0.9804 - auc_3: 0.9917 - acc: 0.9451 - val_loss: 0.1176 - val_auc_2: 0.9897 - val_auc_3: 0.9955 - val_acc: 0.9562\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.95622 to 0.95708, saving model to baseline_cnn_ptbdb.h5\n",
      "10476/10476 - 11s - loss: 0.1296 - auc_2: 0.9854 - auc_3: 0.9934 - acc: 0.9525 - val_loss: 0.0926 - val_auc_2: 0.9925 - val_auc_3: 0.9966 - val_acc: 0.9571\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.95708 to 0.95880, saving model to baseline_cnn_ptbdb.h5\n",
      "10476/10476 - 11s - loss: 0.1247 - auc_2: 0.9870 - auc_3: 0.9945 - acc: 0.9502 - val_loss: 0.1063 - val_auc_2: 0.9914 - val_auc_3: 0.9963 - val_acc: 0.9588\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95880\n",
      "10476/10476 - 10s - loss: 0.1080 - auc_2: 0.9900 - auc_3: 0.9957 - acc: 0.9601 - val_loss: 0.0920 - val_auc_2: 0.9924 - val_auc_3: 0.9959 - val_acc: 0.9588\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.95880 to 0.97511, saving model to baseline_cnn_ptbdb.h5\n",
      "10476/10476 - 11s - loss: 0.0863 - auc_2: 0.9931 - auc_3: 0.9968 - acc: 0.9687 - val_loss: 0.0657 - val_auc_2: 0.9970 - val_auc_3: 0.9987 - val_acc: 0.9751\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.97511 to 0.97854, saving model to baseline_cnn_ptbdb.h5\n",
      "10476/10476 - 11s - loss: 0.0902 - auc_2: 0.9923 - auc_3: 0.9964 - acc: 0.9678 - val_loss: 0.0554 - val_auc_2: 0.9973 - val_auc_3: 0.9989 - val_acc: 0.9785\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.97854 to 0.98455, saving model to baseline_cnn_ptbdb.h5\n",
      "10476/10476 - 11s - loss: 0.0791 - auc_2: 0.9939 - auc_3: 0.9970 - acc: 0.9716 - val_loss: 0.0572 - val_auc_2: 0.9975 - val_auc_3: 0.9989 - val_acc: 0.9845\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98455\n",
      "10476/10476 - 11s - loss: 0.0738 - auc_2: 0.9949 - auc_3: 0.9977 - acc: 0.9735 - val_loss: 0.0531 - val_auc_2: 0.9961 - val_auc_3: 0.9978 - val_acc: 0.9803\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98455\n",
      "10476/10476 - 11s - loss: 0.0694 - auc_2: 0.9951 - auc_3: 0.9978 - acc: 0.9767 - val_loss: 0.0612 - val_auc_2: 0.9949 - val_auc_3: 0.9964 - val_acc: 0.9785\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98455\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "10476/10476 - 12s - loss: 0.0702 - auc_2: 0.9951 - auc_3: 0.9977 - acc: 0.9749 - val_loss: 0.0506 - val_auc_2: 0.9963 - val_auc_3: 0.9978 - val_acc: 0.9828\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.98455 to 0.98970, saving model to baseline_cnn_ptbdb.h5\n",
      "10476/10476 - 11s - loss: 0.0324 - auc_2: 0.9990 - auc_3: 0.9995 - acc: 0.9880 - val_loss: 0.0399 - val_auc_2: 0.9974 - val_auc_3: 0.9982 - val_acc: 0.9897\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.98970 to 0.99142, saving model to baseline_cnn_ptbdb.h5\n",
      "10476/10476 - 11s - loss: 0.0282 - auc_2: 0.9984 - auc_3: 0.9990 - acc: 0.9913 - val_loss: 0.0399 - val_auc_2: 0.9965 - val_auc_3: 0.9979 - val_acc: 0.9914\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99142\n",
      "10476/10476 - 11s - loss: 0.0244 - auc_2: 0.9992 - auc_3: 0.9995 - acc: 0.9916 - val_loss: 0.0387 - val_auc_2: 0.9971 - val_auc_3: 0.9982 - val_acc: 0.9888\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99142\n",
      "10476/10476 - 11s - loss: 0.0222 - auc_2: 0.9992 - auc_3: 0.9995 - acc: 0.9925 - val_loss: 0.0378 - val_auc_2: 0.9967 - val_auc_3: 0.9980 - val_acc: 0.9897\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99142\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "10476/10476 - 11s - loss: 0.0210 - auc_2: 0.9996 - auc_3: 0.9999 - acc: 0.9923 - val_loss: 0.0350 - val_auc_2: 0.9960 - val_auc_3: 0.9970 - val_acc: 0.9914\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99142\n",
      "10476/10476 - 11s - loss: 0.0198 - auc_2: 0.9994 - auc_3: 0.9997 - acc: 0.9926 - val_loss: 0.0352 - val_auc_2: 0.9959 - val_auc_3: 0.9970 - val_acc: 0.9914\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99142\n",
      "10476/10476 - 11s - loss: 0.0188 - auc_2: 0.9993 - auc_3: 0.9996 - acc: 0.9933 - val_loss: 0.0351 - val_auc_2: 0.9973 - val_auc_3: 0.9983 - val_acc: 0.9914\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model1.predict(X_test)\n",
    "pred_test = (pred_test>0.5).astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "993bbf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9918854415274463 \n",
      "Test accuracy score : 0.9883201648917898 \n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab7c08",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370002b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = get_model2()\n",
    "file_path = \"model2_cnn_ptbdb.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d14d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model2.predict(X_test)\n",
    "pred_test = (pred_test>0.5).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6894da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a25c6f",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbbb85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = get_model3()\n",
    "file_path = \"model3_cnn_ptbdb.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa010b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model3.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model3.predict(X_test)\n",
    "pred_test = (pred_test>0.5).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e7265",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db222a",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295dfda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = get_model4()\n",
    "file_path = \"model4_cnn_ptbdb.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bcf9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "history4 = model4.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model4.predict(X_test)\n",
    "pred_test = (pred_test>0.5).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e60ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd8486",
   "metadata": {},
   "source": [
    "# Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82951f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = get_model5()\n",
    "file_path = \"model5_cnn_ptbdb.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history5 = model5.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model5.predict(X_test)\n",
    "pred_test = (pred_test>0.5).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e435ac",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9799c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = get_model6()\n",
    "file_path = \"model6_cnn_ptbdb.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01868ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history6 = model6.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model6.predict(X_test)\n",
    "pred_test = (pred_test>0.5).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5ac025",
   "metadata": {},
   "source": [
    "# Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = get_model7()\n",
    "file_path = \"model7_cnn_ptbdb.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258d515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history7 = model7.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model7.predict(X_test)\n",
    "pred_test = (pred_test>0.5).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9270a0",
   "metadata": {},
   "source": [
    "# Model 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d93ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = get_model8()\n",
    "file_path = \"model8_cnn_ptbdb.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9808f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history8 = model8.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model8.predict(X_test)\n",
    "pred_test = (pred_test>0.5).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea6b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e55b29",
   "metadata": {},
   "source": [
    "# Model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7032c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "model9 = get_model9()\n",
    "file_path = \"model9_cnn_ptbdb.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history9 = model9.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model9.predict(X_test)\n",
    "pred_test = (pred_test>0.5).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e3524",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd98f3e3",
   "metadata": {},
   "source": [
    "# Model 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9564d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model10 = get_model10()\n",
    "file_path = \"model10_cnn_ptbdb.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0751334",
   "metadata": {},
   "outputs": [],
   "source": [
    "history10 = model10.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model10.predict(X_test)\n",
    "pred_test = (pred_test>0.5).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de242d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
