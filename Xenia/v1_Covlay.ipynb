{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f227ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e67541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"C:/00ETH/ml4h/Project1/archive/ptbdb_normal.csv\", header=None)\n",
    "df_2 = pd.read_csv(\"C:/00ETH/ml4h/Project1/archive/ptbdb_abnormal.csv\", header=None)\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
    "\n",
    "\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0de8c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    nclass = 1\n",
    "    inp = Input(shape=(187, 1))\n",
    "    img_1 = Convolution1D(32, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(32, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52d1f878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auroc(Y_test, pred_test):\n",
    "    score = tf.py_func(roc_auc_score,(Y_test, pred_test), tf.double)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0992c67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 187, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 183, 32)           192       \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 179, 32)           5152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 89, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 89, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 87, 64)            6208      \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 85, 64)            12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 42, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 42, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 40, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 38, 64)            12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 19, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 19, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 17, 256)           49408     \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 315,553\n",
      "Trainable params: 315,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "file_path = \"baseline_cnn_ptbdb.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9ee2498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1000\n",
      " - 7s - loss: 0.4951 - acc: 0.7513 - val_loss: 0.4013 - val_acc: 0.8077\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.80773, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 2/1000\n",
      " - 6s - loss: 0.3277 - acc: 0.8615 - val_loss: 0.3310 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.80773 to 0.84206, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 3/1000\n",
      " - 7s - loss: 0.2621 - acc: 0.8958 - val_loss: 0.2172 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.84206 to 0.91674, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 4/1000\n",
      " - 7s - loss: 0.2191 - acc: 0.9130 - val_loss: 0.2055 - val_acc: 0.9142\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91674\n",
      "Epoch 5/1000\n",
      " - 7s - loss: 0.1751 - acc: 0.9316 - val_loss: 0.1366 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91674 to 0.93820, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 6/1000\n",
      " - 7s - loss: 0.1421 - acc: 0.9464 - val_loss: 0.1206 - val_acc: 0.9579\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.93820 to 0.95794, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 7/1000\n",
      " - 7s - loss: 0.1232 - acc: 0.9520 - val_loss: 0.1063 - val_acc: 0.9554\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95794\n",
      "Epoch 8/1000\n",
      " - 7s - loss: 0.1050 - acc: 0.9605 - val_loss: 0.0887 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.95794 to 0.96910, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 9/1000\n",
      " - 7s - loss: 0.0953 - acc: 0.9650 - val_loss: 0.0849 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.96910\n",
      "Epoch 10/1000\n",
      " - 6s - loss: 0.0792 - acc: 0.9712 - val_loss: 0.0687 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.96910 to 0.97597, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 11/1000\n",
      " - 7s - loss: 0.0769 - acc: 0.9720 - val_loss: 0.0855 - val_acc: 0.9682\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.97597\n",
      "Epoch 12/1000\n",
      " - 7s - loss: 0.0624 - acc: 0.9782 - val_loss: 0.1006 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.97597\n",
      "Epoch 13/1000\n",
      " - 7s - loss: 0.0604 - acc: 0.9783 - val_loss: 0.0515 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.97597 to 0.98541, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 14/1000\n",
      " - 7s - loss: 0.0562 - acc: 0.9792 - val_loss: 0.0621 - val_acc: 0.9777\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98541\n",
      "Epoch 15/1000\n",
      " - 6s - loss: 0.0550 - acc: 0.9799 - val_loss: 0.0472 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98541\n",
      "Epoch 16/1000\n",
      " - 7s - loss: 0.0454 - acc: 0.9839 - val_loss: 0.0598 - val_acc: 0.9785\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98541\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 17/1000\n",
      " - 6s - loss: 0.0231 - acc: 0.9922 - val_loss: 0.0326 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.98541 to 0.98970, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 18/1000\n",
      " - 6s - loss: 0.0180 - acc: 0.9942 - val_loss: 0.0291 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.98970 to 0.99142, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 19/1000\n",
      " - 6s - loss: 0.0161 - acc: 0.9945 - val_loss: 0.0277 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99142\n",
      "Epoch 20/1000\n",
      " - 6s - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0252 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.99142 to 0.99227, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 21/1000\n",
      " - 6s - loss: 0.0107 - acc: 0.9963 - val_loss: 0.0263 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99227\n",
      "Epoch 22/1000\n",
      " - 6s - loss: 0.0105 - acc: 0.9963 - val_loss: 0.0275 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99227\n",
      "Epoch 23/1000\n",
      " - 6s - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0231 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.99227 to 0.99313, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 24/1000\n",
      " - 6s - loss: 0.0096 - acc: 0.9968 - val_loss: 0.0222 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99313\n",
      "Epoch 25/1000\n",
      " - 6s - loss: 0.0122 - acc: 0.9955 - val_loss: 0.0212 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99313\n",
      "Epoch 26/1000\n",
      " - 6s - loss: 0.0081 - acc: 0.9968 - val_loss: 0.0242 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.99313\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 27/1000\n",
      " - 6s - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0235 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.99313 to 0.99399, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 28/1000\n",
      " - 6s - loss: 0.0091 - acc: 0.9970 - val_loss: 0.0233 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.99399\n",
      "Epoch 29/1000\n",
      " - 6s - loss: 0.0085 - acc: 0.9968 - val_loss: 0.0236 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.99399\n",
      "Epoch 30/1000\n",
      " - 6s - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0237 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.99399\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 31/1000\n",
      " - 6s - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0235 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.99399\n",
      "Epoch 32/1000\n",
      " - 6s - loss: 0.0075 - acc: 0.9969 - val_loss: 0.0235 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.99399\n",
      "Epoch 00032: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model.predict(X_test)\n",
    "pred_test = (pred_test>0.5).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "993bbf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.997384066587396 \n",
      "Test accuracy score : 0.9962212298179319 \n",
      "Test accuracy score : Tensor(\"PyFunc_1:0\", dtype=float64) \n"
     ]
    }
   ],
   "source": [
    "\n",
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e69ce40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10476 samples, validate on 1165 samples\n",
      "Epoch 1/1000\n",
      " - 7s - loss: 0.5026 - acc: 0.7410 - auroc: 0.7691 - val_loss: 0.4115 - val_acc: 0.8283 - val_auroc: 0.8750\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.82833, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 2/1000\n",
      " - 6s - loss: 0.3342 - acc: 0.8627 - auroc: 0.9192 - val_loss: 0.2533 - val_acc: 0.9013 - val_auroc: 0.9602\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.82833 to 0.90129, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 3/1000\n",
      " - 6s - loss: 0.2332 - acc: 0.9079 - auroc: 0.9596 - val_loss: 0.1685 - val_acc: 0.9425 - val_auroc: 0.9730\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90129 to 0.94249, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 4/1000\n",
      " - 6s - loss: 0.1895 - acc: 0.9284 - auroc: 0.9758 - val_loss: 0.1645 - val_acc: 0.9433 - val_auroc: 0.9821\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94249 to 0.94335, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 5/1000\n",
      " - 6s - loss: 0.1521 - acc: 0.9443 - auroc: 0.9824 - val_loss: 0.1349 - val_acc: 0.9536 - val_auroc: 0.9870\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.94335 to 0.95365, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 6/1000\n",
      " - 6s - loss: 0.1324 - acc: 0.9541 - auroc: 0.9886 - val_loss: 0.1172 - val_acc: 0.9597 - val_auroc: 0.9884\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.95365 to 0.95966, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 7/1000\n",
      " - 6s - loss: 0.1152 - acc: 0.9587 - auroc: 0.9893 - val_loss: 0.0866 - val_acc: 0.9691 - val_auroc: 0.9941\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.95966 to 0.96910, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 8/1000\n",
      " - 6s - loss: 0.0964 - acc: 0.9647 - auroc: 0.9925 - val_loss: 0.0729 - val_acc: 0.9768 - val_auroc: 0.9965\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.96910 to 0.97682, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 9/1000\n",
      " - 6s - loss: 0.1010 - acc: 0.9645 - auroc: 0.9930 - val_loss: 0.0912 - val_acc: 0.9648 - val_auroc: 0.9937\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.97682\n",
      "Epoch 10/1000\n",
      " - 6s - loss: 0.0795 - acc: 0.9714 - auroc: 0.9953 - val_loss: 0.0870 - val_acc: 0.9708 - val_auroc: 0.9935\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.97682\n",
      "Epoch 11/1000\n",
      " - 6s - loss: 0.0678 - acc: 0.9755 - auroc: 0.9963 - val_loss: 0.1059 - val_acc: 0.9571 - val_auroc: 0.9943\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.97682\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/1000\n",
      " - 6s - loss: 0.0456 - acc: 0.9831 - auroc: 0.9978 - val_loss: 0.0457 - val_acc: 0.9837 - val_auroc: 0.9984\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.97682 to 0.98369, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 13/1000\n",
      " - 6s - loss: 0.0310 - acc: 0.9891 - auroc: 0.9992 - val_loss: 0.0426 - val_acc: 0.9837 - val_auroc: 0.9986\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98369\n",
      "Epoch 14/1000\n",
      " - 6s - loss: 0.0304 - acc: 0.9899 - auroc: 0.9991 - val_loss: 0.0388 - val_acc: 0.9880 - val_auroc: 0.9986\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.98369 to 0.98798, saving model to baseline_cnn_ptbdb.h5\n",
      "Epoch 15/1000\n",
      " - 6s - loss: 0.0283 - acc: 0.9904 - auroc: 0.9992 - val_loss: 0.0410 - val_acc: 0.9863 - val_auroc: 0.9986\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98798\n",
      "Epoch 16/1000\n",
      " - 6s - loss: 0.0264 - acc: 0.9905 - auroc: 0.9995 - val_loss: 0.0382 - val_acc: 0.9871 - val_auroc: 0.9990\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98798\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\nTraceback (most recent call last):\n\n  File \"C:\\Users\\user\\Anaconda\\envs\\ml4h\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 209, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\user\\Anaconda\\envs\\ml4h\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 572, in roc_auc_score\n    sample_weight=sample_weight,\n\n  File \"C:\\Users\\user\\Anaconda\\envs\\ml4h\\lib\\site-packages\\sklearn\\metrics\\_base.py\", line 75, in _average_binary_score\n    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n\n  File \"C:\\Users\\user\\Anaconda\\envs\\ml4h\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 338, in _binary_roc_auc_score\n    \"Only one class present in y_true. ROC AUC score \"\n\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n\n\n\t [[{{node metrics_8/auroc/PyFunc}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5036\\3270420294.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mauroc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda\\envs\\ml4h\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda\\envs\\ml4h\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\ml4h\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\ml4h\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\ml4h\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\nTraceback (most recent call last):\n\n  File \"C:\\Users\\user\\Anaconda\\envs\\ml4h\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 209, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\user\\Anaconda\\envs\\ml4h\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 572, in roc_auc_score\n    sample_weight=sample_weight,\n\n  File \"C:\\Users\\user\\Anaconda\\envs\\ml4h\\lib\\site-packages\\sklearn\\metrics\\_base.py\", line 75, in _average_binary_score\n    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n\n  File \"C:\\Users\\user\\Anaconda\\envs\\ml4h\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 338, in _binary_roc_auc_score\n    \"Only one class present in y_true. ROC AUC score \"\n\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n\n\n\t [[{{node metrics_8/auroc/PyFunc}}]]"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy',auroc])\n",
    "model.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a61dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
